{"nbformat_minor": 0, "cells": [{"execution_count": 36, "cell_type": "code", "source": "#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n\"\"\"\nYour task is to use the iterative parsing to process the map file and\nfind out not only what tags are there, but also how many, to get the\nfeeling on how much of which data you can expect to have in the map.\nThe output should be a dictionary with the tag name as the key\nand number of times this tag can be encountered in the map as value.\n\n\"\"\"\nimport xml.etree.ElementTree as ET\nimport pprint\nfrom collections import Counter\n\n\ndef count_tags(filename):\n        lis = []\n        for event,elem in ET.iterparse(filename):\n            lis.append(elem.tag)\n        \n        count_dic = Counter(lis)  \n        return count_dic\n        \n            \n \ndef test():\n    tags = count_tags('example.osm.xml')\n    pprint.pprint(tags)\n  \n\nif __name__ == \"__main__\":\n    test()", "outputs": [{"output_type": "stream", "name": "stdout", "text": "Counter({'node': 20, 'tag': 7, 'nd': 4, 'member': 3, 'bounds': 1, 'relation': 1, 'way': 1, 'osm': 1})\n"}], "metadata": {"collapsed": false, "trusted": true}}, {"execution_count": null, "cell_type": "code", "source": "'''\nAudit street names for ways.\n\n'''\ndef audit():\n    '''\n    every time iterparse see's one of the events specified, in this case 'start', it is going to \n    emit the event and the element that it found.\n    to events we actually pass a tuple and it can be passed any number of recognized events\n    we want iterparse to generate the next item in the iteration when it sees a 'start' tag\n    in python we need to end tuples with a comma\n    '''\n    for event,elem in ET.iterparse(osm_file, events = ('start',)):\n        #the tag property for the elem object that is kicked out has to be 'way'\n        if elem.tag == 'way':\n            #the iter method is designed to return in an iteration all of the subtags nested within\n            #this particular element\n            for tag in elem.iter('tag'):\n                if is_street_name(tag):\n                    audit_street_type(street_types, tag.attrib['v'])\n                    ", "outputs": [], "metadata": {"collapsed": false, "trusted": true}}, {"execution_count": 51, "cell_type": "code", "source": "#!/usr/bin/env python\n# -*- coding: utf-8 -*-\nimport xml.etree.ElementTree as ET\nimport pprint\nimport re\n\"\"\"\nYour task is to explore the data a bit more.\nBefore you process the data and add it into MongoDB, you should\ncheck the \"k\" value for each \"<tag>\" and see if they can be valid keys in MongoDB,\nas well as see if there are any other potential problems.\n\nWe have provided you with 3 regular expressions to check for certain patterns\nin the tags. As we saw in the quiz earlier, we would like to change the data model\nand expand the \"addr:street\" type of keys to a dictionary like this:\n{\"address\": {\"street\": \"Some value\"}}\nSo, we have to see if we have such tags, and if we have any tags with problematic characters.\nPlease complete the function 'key_type'.\n\"\"\"\n\n\nlower = re.compile(r'^([a-z]|_)*$')\nlower_colon = re.compile(r'^([a-z]|_)*:([a-z]|_)*$')\nproblemchars = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n\n\ndef key_type(element, keys):\n    if element.tag == \"tag\":\n        if 'k' in element.attrib:\n            if lower.search(element.attrib['k']):\n                keys['lower'] += 1\n            elif lower_colon.search(element.attrib['k']):\n                keys['lower_colon'] += 1\n            elif problemchars.search(element.attrib['k']):\n                keys['problemchars'] += 1\n            else:\n                keys['other'] += 1        \n    return keys\n\ndef process_map(filename):\n    keys = {\"lower\": 0, \"lower_colon\": 0, \"problemchars\": 0, \"other\": 0}\n    for _, element in ET.iterparse(filename):\n        keys = key_type(element, keys)\n    \n    return keys\n\n\n\ndef test():\n    keys = process_map('example.osm.xml')\n    pprint.pprint(keys)\n\n\nif __name__ == \"__main__\":\n    test()", "outputs": [{"output_type": "stream", "name": "stdout", "text": "{'lower': 7, 'lower_colon': 0, 'other': 0, 'problemchars': 0}\n"}], "metadata": {"collapsed": false, "trusted": true}}, {"execution_count": 64, "cell_type": "code", "source": "#!/usr/bin/env python\n# -*- coding: utf-8 -*-\nimport xml.etree.ElementTree as ET\nimport pprint\nimport re\n\"\"\"\nYour task is to explore the data a bit more.\nThe first task is a fun one - find out how many unique users\nhave contributed to the map in this particular area!\n\nThe function process_map should return a set of unique user IDs (\"uid\")\n\"\"\"\n\ndef get_user(element):\n    return\n\n\ndef process_map(filename):\n    users = set()\n    for _, element in ET.iterparse(filename):\n        if 'uid' in element.attrib:\n            users.add(element.attrib['uid'])\n   \n    return users\n\n\ndef test():\n    users = process_map('example.osm.xml')\n    pprint.pprint(users)\n    #assert len(users) == 6\n\nif __name__ == \"__main__\":\n    test()", "outputs": [{"output_type": "stream", "name": "stdout", "text": "set(['1219059', '147510', '26299', '451048', '567034', '939355'])\n"}], "metadata": {"collapsed": false, "trusted": true}}, {"execution_count": 108, "cell_type": "code", "source": "\"\"\"\nYour task in this exercise has two steps:\n\n- audit the OSMFILE and change the variable 'mapping' to reflect the changes needed to fix \n    the unexpected street types to the appropriate ones in the expected list.\n    You have to add mappings only for the actual problems you find in this OSMFILE,\n    not a generalized solution, since that may and will depend on the particular area you are auditing.\n- write the update_name function, to actually fix the street name.\n    The function takes a string with street name as an argument and should return the fixed name\n    We have provided a simple test so that you see what exactly is expected\n\"\"\"\nimport xml.etree.cElementTree as ET\nfrom collections import defaultdict\nimport re\nimport pprint\n\nOSMFILE = \"example1.osm.xml\"\nstreet_type_re = re.compile(r'\\b\\S+\\.?$', re.IGNORECASE)\n\n\nexpected = [\"Street\", \"Avenue\", \"Boulevard\", \"Drive\", \"Court\", \"Place\", \"Square\", \"Lane\", \"Road\", \n            \"Trail\", \"Parkway\", \"Commons\"]\n\n# UPDATE THIS VARIABLE\nmapping = { \"St\": \"Street\",\n            \"St.\": \"Street\",\n            'Ave': 'Avenue',\n            'Rd.': 'Road'\n            }\n\n\ndef audit_street_type(street_types, street_name):\n    m = street_type_re.search(street_name)\n    if m:\n        street_type = m.group()\n        if street_type not in expected:\n            street_types[street_type].add(street_name)\n\n\ndef is_street_name(elem):\n    return (elem.attrib['k'] == \"addr:street\")\n\n\ndef audit(osmfile):\n    osm_file = open(osmfile, \"r\")\n    street_types = defaultdict(set)\n    for event, elem in ET.iterparse(osm_file, events=(\"start\",)):\n        if elem.tag == \"node\" or elem.tag == \"way\":\n            for tag in elem.iter(\"tag\"):\n                if is_street_name(tag):\n                    audit_street_type(street_types, tag.attrib['v'])\n\n    return street_types\n\n\ndef update_name(name, mapping):\n    split_name = name.split(' ')\n    for word in split_name:\n        for key,value in mapping.items():\n            if word == key:\n                word = mapping[key]\n                split_name.pop()\n                split_name.append(word)\n                new_name = ' '.join(split_name)\n    return new_name\n\n\ndef test():\n    st_types = audit(OSMFILE)\n    #pprint.pprint(dict(st_types))\n    for st_type, ways in st_types.iteritems():\n        for name in ways:\n            better_name = update_name(name, mapping)\n            print name, \"=>\", better_name\n\n\nif __name__ == '__main__':\n    test()", "outputs": [{"output_type": "stream", "name": "stdout", "text": "N. Lincoln Ave => N. Lincoln Avenue\nNorth Lincoln Ave => North Lincoln Avenue\nWest Lexington St. => West Lexington Street\nBaldwin Rd. => Baldwin Road\n"}], "metadata": {"collapsed": false, "trusted": true}}, {"execution_count": null, "cell_type": "code", "source": "#!/usr/bin/env python\n# -*- coding: utf-8 -*-\nimport xml.etree.cElementTree as ET\nimport pprint\nimport re\nimport codecs\nimport json\n\"\"\"\nYour task is to wrangle the data and transform the shape of the data\ninto the model we mentioned earlier. The output should be a list of dictionaries\nthat look like this:\n\n{\n\"id\": \"2406124091\",\n\"type: \"node\",\n\"visible\":\"true\",\n\"created\": {\n          \"version\":\"2\",\n          \"changeset\":\"17206049\",\n          \"timestamp\":\"2013-08-03T16:43:42Z\",\n          \"user\":\"linuxUser16\",\n          \"uid\":\"1219059\"\n        },\n\"pos\": [41.9757030, -87.6921867],\n\"address\": {\n          \"housenumber\": \"5157\",\n          \"postcode\": \"60625\",\n          \"street\": \"North Lincoln Ave\"\n        },\n\"amenity\": \"restaurant\",\n\"cuisine\": \"mexican\",\n\"name\": \"La Cabana De Don Luis\",\n\"phone\": \"1 (773)-271-5176\"\n}\n\nYou have to complete the function 'shape_element'.\nWe have provided a function that will parse the map file, and call the function with the element\nas an argument. You should return a dictionary, containing the shaped data for that element.\nWe have also provided a way to save the data in a file, so that you could use\nmongoimport later on to import the shaped data into MongoDB. \n\nNote that in this exercise we do not use the 'update street name' procedures\nyou worked on in the previous exercise. If you are using this code in your final\nproject, you are strongly encouraged to use the code from previous exercise to \nupdate the street names before you save them to JSON. \n\nIn particular the following things should be done:\n- you should process only 2 types of top level tags: \"node\" and \"way\"\n- all attributes of \"node\" and \"way\" should be turned into regular key/value pairs, except:\n    - attributes in the CREATED array should be added under a key \"created\"\n    - attributes for latitude and longitude should be added to a \"pos\" array,\n      for use in geospacial indexing. Make sure the values inside \"pos\" array are floats\n      and not strings. \n- if the second level tag \"k\" value contains problematic characters, it should be ignored\n- if the second level tag \"k\" value starts with \"addr:\", it should be added to a dictionary \"address\"\n- if the second level tag \"k\" value does not start with \"addr:\", but contains \":\", you can\n  process it in a way that you feel is best. For example, you might split it into a two-level\n  dictionary like with \"addr:\", or otherwise convert the \":\" to create a valid key.\n- if there is a second \":\" that separates the type/direction of a street,\n  the tag should be ignored, for example:\n\n<tag k=\"addr:housenumber\" v=\"5158\"/>\n<tag k=\"addr:street\" v=\"North Lincoln Avenue\"/>\n<tag k=\"addr:street:name\" v=\"Lincoln\"/>\n<tag k=\"addr:street:prefix\" v=\"North\"/>\n<tag k=\"addr:street:type\" v=\"Avenue\"/>\n<tag k=\"amenity\" v=\"pharmacy\"/>\n\n  should be turned into:\n\n{...\n\"address\": {\n    \"housenumber\": 5158,\n    \"street\": \"North Lincoln Avenue\"\n}\n\"amenity\": \"pharmacy\",\n...\n}\n\n- for \"way\" specifically:\n\n  <nd ref=\"305896090\"/>\n  <nd ref=\"1719825889\"/>\n\nshould be turned into\n\"node_refs\": [\"305896090\", \"1719825889\"]\n\"\"\"\n\n\nlower = re.compile(r'^([a-z]|_)*$')\nlower_colon = re.compile(r'^([a-z]|_)*:([a-z]|_)*$')\nproblemchars = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n\nCREATED = [ \"version\", \"changeset\", \"timestamp\", \"user\", \"uid\"]\n\n\ndef shape_element(element):\n    node = {}\n    address = {}\n    pos = []\n    if element.tag == \"node\" or element.tag == \"way\" :\n        # YOUR CODE HERE\n        node[\"id\"] = element.attrib[\"id\"]\n        node[\"type\"] =  element.tag\n        node[ \"visible\"] = element.get(\"visible\")\n        \n        created = {}\n        created[\"version\"] = element.attrib[\"version\"]\n        created[\"changeset\"] = element.attrib[\"changeset\"]\n        created[\"timestamp\"] = element.attrib[\"timestamp\"]\n        created[\"user\"] = element.attrib[\"user\"]\n        created[\"uid\"] = element.attrib[\"uid\"]\n        node[\"created\"] = created\n        if \"lat\" in element.keys() and \"lon\" in element.keys():\n           pos = [element.attrib[\"lat\"], element.attrib[\"lon\"]]        \n           node[\"pos\"] = [float(string) for string in pos]\n        else:\n           node[\"pos\"] = None\n            \n        for tag in element.iter('tag'):\n            if re.search('addr:', tag.attrib['k']):\n                if len(tag.attrib['k'].split(\":\")) < 3:\n                    addr_add = tag.attrib['k'].split(\":\")[1]\n                    address[addr_add] = tag.attrib['v']               \n        if address:\n            node['address'] = address   \n        \n        pprint.pprint(node)\n        return node\n    else:\n        return None\n        \n\n\ndef process_map(file_in, pretty = False):\n    # You do not need to change this file\n    file_out = \"{0}.json\".format(file_in)\n    data = []\n    with codecs.open(file_out, \"w\") as fo:\n        for _, element in ET.iterparse(file_in):\n            el = shape_element(element)\n            if el:\n                data.append(el)\n                if pretty:\n                    fo.write(json.dumps(el, indent=2)+\"\\n\")\n                else:\n                    fo.write(json.dumps(el) + \"\\n\")\n    return data\n\ndef test():\n    # NOTE: if you are running this code on your computer, with a larger dataset, \n    # call the process_map procedure with pretty=False. The pretty=True option adds \n    # additional spaces to the output, making it significantly larger.\n    data = process_map('example.osm', True)\n    #pprint.pprint(data)\n    \n    correct_first_elem = {\n        \"id\": \"261114295\", \n        \"visible\": \"true\", \n        \"type\": \"node\", \n        \"pos\": [41.9730791, -87.6866303], \n        \"created\": {\n            \"changeset\": \"11129782\", \n            \"user\": \"bbmiller\", \n            \"version\": \"7\", \n            \"uid\": \"451048\", \n            \"timestamp\": \"2012-03-28T18:31:23Z\"\n        }\n    }\n    assert data[0] == correct_first_elem\n    assert data[-1][\"address\"] == {\n                                    \"street\": \"West Lexington St.\", \n                                    \"housenumber\": \"1412\"\n                                      }\n    assert data[-1][\"node_refs\"] == [ \"2199822281\", \"2199822390\",  \"2199822392\", \"2199822369\", \n                                    \"2199822370\", \"2199822284\", \"2199822281\"]\n\nif __name__ == \"__main__\":\n    test()", "outputs": [], "metadata": {"collapsed": true, "trusted": true}}], "nbformat": 4, "metadata": {"kernelspec": {"display_name": "Python 2", "name": "python2", "language": "python"}, "language_info": {"mimetype": "text/x-python", "nbconvert_exporter": "python", "version": "2.7.9", "name": "python", "file_extension": ".py", "pygments_lexer": "ipython2", "codemirror_mode": {"version": 2, "name": "ipython"}}}}